{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/dalloliogm/autogluon-approach-to-fertilizer-prediction?scriptVersionId=243022174\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Autogluon approach\n\nAutogluon is an autoML tool from Amazon. It performed well in previous playground competitions. Let's try it out.","metadata":{}},{"cell_type":"code","source":"# Go to Add-ons > Install Dependencies to install this into the environment\n!pip install -q autogluon","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T07:42:26.465163Z","iopub.execute_input":"2025-06-01T07:42:26.466418Z","iopub.status.idle":"2025-06-01T07:42:33.38213Z","shell.execute_reply.started":"2025-06-01T07:42:26.466388Z","shell.execute_reply":"2025-06-01T07:42:33.380427Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"## Parameters","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport polars as pl\nimport numpy as np\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import train_test_split\n\ndef is_interactive_session():\n    return os.environ.get('KAGGLE_KERNEL_RUN_TYPE','') == 'Interactive'\n\nis_interactive_session()\n\nconfig = {\n    \"autogluon_time\": 3600,\n    \"autogluon_presets\": \"best_quality\",\n    #\"reduce_features\": 0, # Set to >0 to use only the first n features\n    \"tail_rows\": 0 # Set to >0 to use only the last n rows in the file\n    \n}\n\nif is_interactive_session():\n    print(\"Interactive session\")\n    config[\"autogluon_time\"] = 100\n    #config[\"reduce_features\"] = 200\n    config[\"autogluon_presets\"] = \"medium_quality\"\n    config[\"tail_rows\"] = 2000\n    print(config)\nelse:\n    print(\"running as job\")\n    print(config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T07:42:33.384479Z","iopub.execute_input":"2025-06-01T07:42:33.384875Z","iopub.status.idle":"2025-06-01T07:42:34.019988Z","shell.execute_reply.started":"2025-06-01T07:42:33.384837Z","shell.execute_reply":"2025-06-01T07:42:34.018988Z"}},"outputs":[{"name":"stdout","text":"Interactive session\n{'autogluon_time': 100, 'autogluon_presets': 'medium_quality', 'tail_rows': 2000}\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"## Read data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ntrain = pd.read_csv('/kaggle/input/playground-series-s5e6/train.csv')\ntest = pd.read_csv('/kaggle/input/playground-series-s5e6/test.csv')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-01T07:42:34.020867Z","iopub.execute_input":"2025-06-01T07:42:34.021149Z","iopub.status.idle":"2025-06-01T07:42:35.100427Z","shell.execute_reply.started":"2025-06-01T07:42:34.021129Z","shell.execute_reply":"2025-06-01T07:42:35.099681Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T07:42:35.102135Z","iopub.execute_input":"2025-06-01T07:42:35.102452Z","iopub.status.idle":"2025-06-01T07:42:35.114352Z","shell.execute_reply.started":"2025-06-01T07:42:35.102429Z","shell.execute_reply":"2025-06-01T07:42:35.113533Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"   id  Temparature  Humidity  Moisture Soil Type  Crop Type  Nitrogen  \\\n0   0           37        70        36    Clayey  Sugarcane        36   \n1   1           27        69        65     Sandy    Millets        30   \n2   2           29        63        32     Sandy    Millets        24   \n3   3           35        62        54     Sandy     Barley        39   \n4   4           35        58        43       Red      Paddy        37   \n\n   Potassium  Phosphorous Fertilizer Name  \n0          4            5           28-28  \n1          6           18           28-28  \n2         12           16        17-17-17  \n3         12            4        10-26-26  \n4          2           16             DAP  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Temparature</th>\n      <th>Humidity</th>\n      <th>Moisture</th>\n      <th>Soil Type</th>\n      <th>Crop Type</th>\n      <th>Nitrogen</th>\n      <th>Potassium</th>\n      <th>Phosphorous</th>\n      <th>Fertilizer Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>37</td>\n      <td>70</td>\n      <td>36</td>\n      <td>Clayey</td>\n      <td>Sugarcane</td>\n      <td>36</td>\n      <td>4</td>\n      <td>5</td>\n      <td>28-28</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>27</td>\n      <td>69</td>\n      <td>65</td>\n      <td>Sandy</td>\n      <td>Millets</td>\n      <td>30</td>\n      <td>6</td>\n      <td>18</td>\n      <td>28-28</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>29</td>\n      <td>63</td>\n      <td>32</td>\n      <td>Sandy</td>\n      <td>Millets</td>\n      <td>24</td>\n      <td>12</td>\n      <td>16</td>\n      <td>17-17-17</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>35</td>\n      <td>62</td>\n      <td>54</td>\n      <td>Sandy</td>\n      <td>Barley</td>\n      <td>39</td>\n      <td>12</td>\n      <td>4</td>\n      <td>10-26-26</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>35</td>\n      <td>58</td>\n      <td>43</td>\n      <td>Red</td>\n      <td>Paddy</td>\n      <td>37</td>\n      <td>2</td>\n      <td>16</td>\n      <td>DAP</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"from autogluon.tabular import TabularPredictor\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T07:42:35.115653Z","iopub.execute_input":"2025-06-01T07:42:35.116048Z","iopub.status.idle":"2025-06-01T07:42:35.127495Z","shell.execute_reply.started":"2025-06-01T07:42:35.116015Z","shell.execute_reply":"2025-06-01T07:42:35.12665Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"## Some Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"### Nutrient Ratios\n\nFertilizers are often chosen based on nutrient balance, not just raw amounts.\n\n","metadata":{}},{"cell_type":"code","source":"train['N_P_ratio'] = train['Nitrogen'] / (train['Phosphorous'] + 1)\ntrain['N_K_ratio'] = train['Nitrogen'] / (train['Potassium'] + 1)\ntrain['P_K_ratio'] = train['Phosphorous'] / (train['Potassium'] + 1)\ntest['N_P_ratio'] = test['Nitrogen'] / (test['Phosphorous'] + 1)\ntest['N_K_ratio'] = test['Nitrogen'] / (test['Potassium'] + 1)\ntest['P_K_ratio'] = test['Phosphorous'] / (test['Potassium'] + 1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T07:46:04.032837Z","iopub.execute_input":"2025-06-01T07:46:04.033605Z","iopub.status.idle":"2025-06-01T07:46:04.06529Z","shell.execute_reply.started":"2025-06-01T07:46:04.033575Z","shell.execute_reply":"2025-06-01T07:46:04.064523Z"}},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":"### Weather Soil Interactions","metadata":{}},{"cell_type":"code","source":"train['Temp_Humidity'] = train['Temparature'] * train['Humidity']\ntrain['Soil_Crop'] = train['Soil Type'] + '_' + train['Crop Type']\ntest['Temp_Humidity'] = test['Temparature'] * test['Humidity']\ntest['Soil_Crop'] = test['Soil Type'] + '_' + test['Crop Type']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T07:46:05.391099Z","iopub.execute_input":"2025-06-01T07:46:05.391427Z","iopub.status.idle":"2025-06-01T07:46:05.660898Z","shell.execute_reply.started":"2025-06-01T07:46:05.391404Z","shell.execute_reply":"2025-06-01T07:46:05.66007Z"}},"outputs":[],"execution_count":36},{"cell_type":"markdown","source":"### Polynomial binning","metadata":{}},{"cell_type":"code","source":"# Bin temparature\ntrain['Temp_bin'] = pd.cut(train['Temparature'], bins=[0, 20, 30, 40, 60], labels=['Low', 'Med', 'High', 'Very High'])\n# Combine with crop\ntrain['Crop_Temp_bin'] = train['Crop Type'] + '_' + train['Temp_bin'].astype(str)\n\n\ntest['Temp_bin'] = pd.cut(test['Temparature'], bins=[0, 20, 30, 40, 60], labels=['Low', 'Med', 'High', 'Very High'])\n# Combine with crop\ntest['Crop_Temp_bin'] = test['Crop Type'] + '_' + test['Temp_bin'].astype(str)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T07:46:07.895209Z","iopub.execute_input":"2025-06-01T07:46:07.895543Z","iopub.status.idle":"2025-06-01T07:46:08.450285Z","shell.execute_reply.started":"2025-06-01T07:46:07.895512Z","shell.execute_reply":"2025-06-01T07:46:08.449395Z"}},"outputs":[],"execution_count":37},{"cell_type":"markdown","source":"## Train Predictor\n\nAutogluon will try several models and parameters. To trigger the training, just call .fit().","metadata":{}},{"cell_type":"code","source":"label = 'Fertilizer Name'\npredictor = TabularPredictor(label=\"Fertilizer Name\", \n                            eval_metric=\"log_loss\").\\\n                fit(\n                            train,\n                            presets=config[\"autogluon_presets\"],\n                            time_limit=config[\"autogluon_time\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T07:42:35.885236Z","iopub.execute_input":"2025-06-01T07:42:35.885832Z","iopub.status.idle":"2025-06-01T07:44:20.87758Z","shell.execute_reply.started":"2025-06-01T07:42:35.885802Z","shell.execute_reply":"2025-06-01T07:44:20.876804Z"}},"outputs":[{"name":"stderr","text":"No path specified. Models will be saved in: \"AutogluonModels/ag-20250601_074235\"\nVerbosity: 2 (Standard Logging)\n=================== System Info ===================\nAutoGluon Version:  1.3.1\nPython Version:     3.11.11\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #1 SMP PREEMPT_DYNAMIC Sun Nov 10 10:07:59 UTC 2024\nCPU Count:          4\nMemory Avail:       28.97 GB / 31.35 GB (92.4%)\nDisk Space Avail:   19.26 GB / 19.52 GB (98.7%)\n===================================================\nPresets specified: ['medium_quality']\nBeginning AutoGluon training ... Time limit = 100s\nAutoGluon will save models to \"/kaggle/working/AutogluonModels/ag-20250601_074235\"\nTrain Data Rows:    750000\nTrain Data Columns: 16\nLabel Column:       Fertilizer Name\nAutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n\t7 unique label values:  ['28-28', '17-17-17', '10-26-26', 'DAP', '20-20', '14-35-14', 'Urea']\n\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\nProblem Type:       multiclass\nPreprocessing data ...\nTrain Data Class Count: 7\nUsing Feature Generators to preprocess the data ...\nFitting AutoMLPipelineFeatureGenerator...\n\tAvailable Memory:                    29779.03 MB\n\tTrain Data (Original)  Memory Usage: 252.22 MB (0.8% of available memory)\n\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n\tStage 1 Generators:\n\t\tFitting AsTypeFeatureGenerator...\n\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n\tStage 2 Generators:\n\t\tFitting FillNaFeatureGenerator...\n\tStage 3 Generators:\n\t\tFitting IdentityFeatureGenerator...\n\t\tFitting CategoryFeatureGenerator...\n\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n\tStage 4 Generators:\n\t\tFitting DropUniqueFeatureGenerator...\n\tStage 5 Generators:\n\t\tFitting DropDuplicatesFeatureGenerator...\n\tTypes of features in original data (raw dtype, special dtypes):\n\t\t('category', []) : 1 | ['Temp_bin']\n\t\t('float', [])    : 3 | ['N_P_ratio', 'N_K_ratio', 'P_K_ratio']\n\t\t('int', [])      : 8 | ['id', 'Temparature', 'Humidity', 'Moisture', 'Nitrogen', ...]\n\t\t('object', [])   : 4 | ['Soil Type', 'Crop Type', 'Soil_Crop', 'Crop_Temp_bin']\n\tTypes of features in processed data (raw dtype, special dtypes):\n\t\t('category', [])  : 4 | ['Soil Type', 'Crop Type', 'Soil_Crop', 'Crop_Temp_bin']\n\t\t('float', [])     : 3 | ['N_P_ratio', 'N_K_ratio', 'P_K_ratio']\n\t\t('int', [])       : 8 | ['id', 'Temparature', 'Humidity', 'Moisture', 'Nitrogen', ...]\n\t\t('int', ['bool']) : 1 | ['Temp_bin']\n\t3.1s = Fit runtime\n\t16 features in original data used to generate 16 features in processed data.\n\tTrain Data (Processed) Memory Usage: 66.52 MB (0.2% of available memory)\nData preprocessing and feature engineering runtime = 4.47s ...\nAutoGluon will gauge predictive performance using evaluation metric: 'log_loss'\n\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n\tTo change this, specify the eval_metric parameter of Predictor()\nAutomatically generating train/validation split with holdout_frac=0.01, Train Rows: 742500, Val Rows: 7500\nUser-specified model hyperparameters to be fit:\n{\n\t'NN_TORCH': [{}],\n\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n\t'CAT': [{}],\n\t'XGB': [{}],\n\t'FASTAI': [{}],\n\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n}\nFitting 13 L1 models, fit_strategy=\"sequential\" ...\nFitting model: KNeighborsUnif ... Training model for up to 95.53s of the 95.53s of remaining time.\n\t-8.0944\t = Validation score   (-log_loss)\n\t1.97s\t = Training   runtime\n\t0.04s\t = Validation runtime\nFitting model: KNeighborsDist ... Training model for up to 93.16s of the 93.16s of remaining time.\n\t-8.1035\t = Validation score   (-log_loss)\n\t1.93s\t = Training   runtime\n\t0.04s\t = Validation runtime\nFitting model: NeuralNetFastAI ... Training model for up to 90.86s of the 90.85s of remaining time.\n\tRan out of time, stopping training early. (Stopping on epoch 4)\n\t-1.9378\t = Validation score   (-log_loss)\n\t85.44s\t = Training   runtime\n\t0.07s\t = Validation runtime\nFitting model: LightGBMXT ... Training model for up to 5.27s of the 5.27s of remaining time.\n\tRan out of time, early stopping on iteration 11. Best iteration is:\n\t[11]\tvalid_set's multi_logloss: 1.93926\n\t-1.9393\t = Validation score   (-log_loss)\n\t5.41s\t = Training   runtime\n\t0.04s\t = Validation runtime\nFitting model: WeightedEnsemble_L2 ... Training model for up to 95.53s of the -0.21s of remaining time.\n\tEnsemble Weights: {'NeuralNetFastAI': 0.8, 'LightGBMXT': 0.2}\n\t-1.9377\t = Validation score   (-log_loss)\n\t0.45s\t = Training   runtime\n\t0.01s\t = Validation runtime\nAutoGluon training complete, total runtime = 101.21s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 60630.8 rows/s (7500 batch size)\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kaggle/working/AutogluonModels/ag-20250601_074235\")\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"probs = predictor.predict_proba(test)  \ntop3_preds = probs.apply(lambda row: row.nlargest(3).index.tolist(), axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T07:46:12.404687Z","iopub.execute_input":"2025-06-01T07:46:12.404984Z","iopub.status.idle":"2025-06-01T07:48:24.945887Z","shell.execute_reply.started":"2025-06-01T07:46:12.404965Z","shell.execute_reply":"2025-06-01T07:48:24.945067Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"# from sklearn.metrics import label_ranking_average_precision_score\n# import numpy as np\n\n# # Ground truth as binary indicator matrix\n# y_true = pd.get_dummies(test['Fertilizer Name']).values\n# y_score = probs[test.columns[1:]]  # drop 'id'\n\n# map3 = label_ranking_average_precision_score(y_true, y_score)\n# print(f'MAP@3: {map3:.4f}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T07:56:15.473967Z","iopub.execute_input":"2025-06-01T07:56:15.474794Z","iopub.status.idle":"2025-06-01T07:56:15.478696Z","shell.execute_reply.started":"2025-06-01T07:56:15.474763Z","shell.execute_reply":"2025-06-01T07:56:15.477669Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Get leaderboard with scores\nlb = predictor.leaderboard(silent=True)\n\n# Filter only models with valid CV scores\nlb = lb[~lb['score_val'].isna()]\n\n# Plot\nplt.figure(figsize=(10, 6))\nsns.barplot(data=lb, x='score_val', y='model', palette='viridis')\nplt.xlabel('CV Score (MAP@3)')\nplt.ylabel('Model')\nplt.title('Cross-Validation Scores for AutoGluon Models')\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def mapk(y_true, y_pred, k=3):\n#     def apk(actual, predicted, k):\n#         predicted = predicted[:k]\n#         score = 0.0\n#         num_hits = 0.0\n#         for i, p in enumerate(predicted):\n#             if p == actual and p not in predicted[:i]:\n#                 num_hits += 1.0\n#                 score += num_hits / (i + 1.0)\n#                 break  # Only the first correct label counts\n#         return score\n\n#     return np.mean([apk(a, p, k) for a, p in zip(y_true, y_pred)])\n\n# # Use it:\n# true_labels = val[\"Fertilizer Name\"].values\n# map3_score = mapk(true_labels, top3_preds, k=3)\n# print(f\"Strict MAP@3: {map3_score:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T07:56:25.24604Z","iopub.execute_input":"2025-06-01T07:56:25.246829Z","iopub.status.idle":"2025-06-01T07:56:25.250704Z","shell.execute_reply.started":"2025-06-01T07:56:25.246802Z","shell.execute_reply":"2025-06-01T07:56:25.249745Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"probs = predictor.predict_proba(test)\ntop3 = probs.apply(lambda x: ' '.join(x.nlargest(3).index), axis=1)\nsubmission = pd.DataFrame({'id': test['id'], 'Fertilizer Name': top3})\nsubmission.to_csv('submission.csv', index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T07:56:26.745499Z","iopub.execute_input":"2025-06-01T07:56:26.745818Z"}},"outputs":[],"execution_count":null}]}